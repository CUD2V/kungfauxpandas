{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# flag to control where data is loaded to\n",
    "mode = 'sqlite3'\n",
    "\n",
    "# sqlite stuff\n",
    "if mode == 'sqlite3':\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(\"../../../data/sample_data.db\")\n",
    "    cursor = conn.cursor()\n",
    "elif mode == 'psycopg2': # alternatively use postgresql\n",
    "    import psycopg2\n",
    "    connect_str = \"dbname='sepsis' user='sepsis' host='localhost' \" + \\\n",
    "                  \"password='sepsis'\"\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "qlog_conn = sqlite3.connect('../../../data/kfp_log.db')\n",
    "q_cursor = qlog_conn.cursor()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "# because names are created as case sensistive in postgres, must be quoted...\n",
    "# should probably fix that...\n",
    "sql = '''\n",
    "SELECT d.\"SubjectId\",\n",
    "    d.\"EncounterId\",\n",
    "    d.\"Source\",\n",
    "    -- d.\"StartDate\",\n",
    "    d.\"Code\",\n",
    "    d.\"Type\",\n",
    "     MAX(\"FlowsheetValue\") AS MaxScore,\n",
    "     AVG(\"FlowsheetValue\") AS MeanScore,\n",
    "     MIN(\"FlowsheetValue\") AS MinScore,\n",
    "     COUNT(\"FlowsheetValue\") AS NumLoggedScores\n",
    " FROM diagnoses d\n",
    " LEFT JOIN flowsheet f\n",
    " ON d.\"EncounterId\" = f.\"EncounterId\"\n",
    "-- GROUP BY d.\"SubjectId\", d.\"EncounterId\", d.\"Source\", d.\"StartDate\", d.\"Code\", d.\"Type\"\n",
    " GROUP BY d.\"SubjectId\", d.\"EncounterId\", d.\"Source\", d.\"Code\", d.\"Type\"\n",
    " ORDER BY NumLoggedScores DESC\n",
    " limit 100\n",
    "'''\n",
    "\n",
    "#sql = 'SELECT subjectid, encounterid, source, code, type FROM \"diagnoses\" limit 100'\n",
    "\n",
    "\n",
    "#df = pd.read_sql(sql,conn, index_col=['SubjectId', 'EncounterId'])\n",
    "df = pd.read_sql(sql,conn)\n",
    "#df['StartDate'] = df['StartDate'].astype('datetime64')\n",
    "# print(df.dtypes)\n",
    "# print('Elapsed time:', datetime.datetime.now() - start)\n",
    "df.head()\n",
    "\n",
    "# sqlite - 42 to 60 seconds\n",
    "# postgres - 29 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_timings(df):\n",
    "    q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "    print('Method used     :', q.tail(1)['faux_method'].iloc[0])\n",
    "    print('Time for query  :', (pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0])\n",
    "    print('Time for fauxify:', (pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0])\n",
    "    print('Size of dataset :', len(df), 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from kungfauxpandas import KungFauxPandas, TrivialPlugin, DataSynthesizerPlugin, KDEPlugin\n",
    "kfpd = KungFauxPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode', verbose=False)\n",
    "#fdf=kfpd.read_sql(sql,conn, index_col=['SubjectId', 'EncounterId'])\n",
    "fdf=kfpd.read_sql(sql,conn)#, fauxify = {'categorical_attributes' : {'Source' : True}})\n",
    "#fdf = kfpd.plugin.fauxify(df)\n",
    "fdf.head()\n",
    "\n",
    "#fdf=kfpd.read_sql(sql,conn, index_col=['SubjectId', 'EncounterId'])\n",
    "#fdf=kfpd.read_sql(sql,conn, fauxify = {'categorical_attributes' : {'Source' : True}})\n",
    "#df=pd.read_sql(sql + ' 10',conn)\n",
    "#fdf = kfpd.plugin.fauxify(df)#, categorical_attributes = {'Source' : True, 'Code': True, 'Type': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = TrivialPlugin()\n",
    "for n in ['10', '100', '1000', '10000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = KDEPlugin()\n",
    "for n in ['10', '100', '1000', '10000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Code'\n",
    "out_dict = dict()\n",
    "\n",
    "colfact = df[col].factorize()\n",
    "cc=Counter(colfact[0])\n",
    " \n",
    "# convert from counts to proportions\n",
    "\n",
    "for key in cc:\n",
    "     cc[key] = cc[key] / len(df)\n",
    "\n",
    "fakes = choice(elements,p=weights, replace=True, size=len(df))\n",
    "\n",
    "out_dict[col] = [colfact[1][xx] for xx in fakes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cc.values()), len(df), len(cc)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Code'\n",
    "out_dict = dict()\n",
    "\n",
    "colfact = df[col].factorize()\n",
    "cc=Counter(colfact[0])\n",
    " \n",
    "# convert from counts to proportions\n",
    "\n",
    "for key in cc:\n",
    "     cc[key] = cc[key] / len(df)\n",
    "\n",
    "fakes = choice(elements,p=weights, replace=True, size=len(df))\n",
    "\n",
    "out_dict[col] = [colfact[1][xx] for xx in fakes]\n",
    "#out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'SubjectId'\n",
    "kd = stats.gaussian_kde(df[col], bw_method='silverman')\n",
    "out_dict[col]=np.int64(kd.resample()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Codeode, df.squishcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df.Code, df.squishcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.sample(50000)\n",
    "for thiscol in sdf.columns:\n",
    "    if sdf[thiscol].dtype=='object':\n",
    "        print('Converting column ', thiscol)\n",
    "        sdf[thiscol] = sdf[thiscol].factorize()[0]\n",
    "    \n",
    "#np.cov(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.corrcoef(sdf.transpose())\n",
    "#cc = np.cov(sdf.transpose())\n",
    "#cc[5,1]\n",
    "plt.imshow(cc,cmap='inferno')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf.head()\n",
    "#help(np.correlate)\n",
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric import kernel_density as kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woo = kd.KDEMultivariate(np.array(sdf.iloc[:,[2,4,9]]), var_type=3*'u')\n",
    "#help(kd.KDEMultivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data=sdf.sample(2000).iloc[:,[2,4,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(40)\n",
    "bb = list(itertools.product(xx,xx,xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sdf.iloc[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# fit\n",
    "kde = woo#  # ... you already did this\n",
    "\n",
    "# sample\n",
    "u = np.random.random()\n",
    "\n",
    "# 1-d root-finding\n",
    "def func(x):\n",
    "    return kde.cdf([x]) - u\n",
    "#sample_x = brentq(func, -99999999, 99999999)  # read brentq-docs about these constants\n",
    "                                              # constants need to be sign-changing for the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u = np.random.random()\n",
    "#u\n",
    "#sample_x = brentq(func, -99999999, 99999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return kde.cdf([x]) - u\n",
    "\n",
    "x0=[92,4,5,3,6,7,8,9,10,11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "darf = minimize(func,np.array(x0))\n",
    "print(darf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, func(x0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func([0,0,0,0,0,3,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bork = np.mgrid[0:10,0:10, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(4)\n",
    "\n",
    "import itertools\n",
    "ins = list(itertools.product(xx,xx,xx,xx,xx,xx,xx,xx,xx,xx))\n",
    "\n",
    "vals = [func(i) for i in ins[1004:2004]]\n",
    "func(ins[1004:2004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(bork[32532])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kde.cdf(bork[9000:10000])\n",
    "func(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bork[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "nobs = 300\n",
    "np.random.seed(1234)  # Seed random generator\n",
    "c1 = np.random.normal(size=(nobs,1))\n",
    "c2 = np.random.normal(2, 1, size=(nobs,1))\n",
    "  \n",
    "#Estimate a bivariate distribution and display the bandwidth found:\n",
    "   \n",
    "#dens_u = sm.nonparametric.KDEMultivariate(data=[c1,c2], var_type='cc', bw='normal_reference')\n",
    "#dens_u.bw\n",
    "\n",
    "woo = sm.nonparametric.KDEMultivariate(data=sdf.iloc[:,[2,4,9]], var_type=3*'u')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woo.cdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(sdf.iloc[:,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(sdf.iloc[:,[2,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
