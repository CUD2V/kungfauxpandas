{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to monitor memory usage while this performance test runs**\n",
    "\n",
    "As this process takes \n",
    "\n",
    "First install psrecord:\n",
    "\n",
    "`pip install psrecord`\n",
    "\n",
    "Next, find your process PID and substitue into the following command (replace PID with the actual integer value):\n",
    "\n",
    "`psrecord PID --interval 10 --plot plot1.png`\n",
    "\n",
    "The above command will monitor the designated PID every 10 seconds until Ctrl-C is pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "# files and kungfauxpandas loading require reference from one directory level up\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "# while not currently plotting, would like to add this feature\n",
    "%matplotlib notebook\n",
    "pd.set_option('display.width', 110)\n",
    "\n",
    "# flag to control where data is loaded to\n",
    "mode = 'psycopg2'\n",
    "\n",
    "# how many times to run each test for tracking mean/std dev\n",
    "\n",
    "# sqlite stuff\n",
    "if mode == 'sqlite3':\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(\"../../data/sample_data.db\")\n",
    "    cursor = conn.cursor()\n",
    "elif mode == 'psycopg2': # alternatively use postgresql\n",
    "    import psycopg2\n",
    "    connect_str = \"dbname='sepsis' user='sepsis' host='localhost' \" + \\\n",
    "                  \"password='sepsis'\"\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "qlog_conn = sqlite3.connect('../../data/kfp_log.db')\n",
    "q_cursor = qlog_conn.cursor()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "# because names are created as case sensistive in postgres, must be quoted...\n",
    "# should probably fix that...\n",
    "sql = '''\n",
    "SELECT d.\"SubjectId\",\n",
    "    d.\"EncounterId\",\n",
    "    d.\"Source\",\n",
    "    -- d.StartDate,\n",
    "    d.\"Code\",\n",
    "    d.\"Type\",\n",
    "    MAX(\"FlowsheetValue\") AS MaxScore,\n",
    "    -- AVG(\"FlowsheetValue\") AS MeanScore,\n",
    "    MIN(\"FlowsheetValue\") AS MinScore,\n",
    "    COUNT(\"FlowsheetValue\") AS NumLoggedScores\n",
    " FROM diagnoses d\n",
    " LEFT JOIN flowsheet f\n",
    " ON d.\"EncounterId\" = f.\"EncounterId\"\n",
    " GROUP BY d.\"SubjectId\", d.\"EncounterId\", d.\"Source\", d.\"Code\", d.\"Type\"\n",
    " ORDER BY NumLoggedScores DESC\n",
    " limit\n",
    "'''\n",
    "# timing this query on databases\n",
    "\n",
    "#start = datetime.datetime.now()\n",
    "#df = pd.read_sql(sql,conn)\n",
    "#print((datetime.datetime.now() - start).total_seconds())\n",
    "# w/no limit - medium sepsis database\n",
    "#   sqlite - 80 to 160 seconds\n",
    "#   postgres - 30 seconds\n",
    "\n",
    "#sql = 'SELECT subjectid, encounterid, source, code, type FROM \"diagnoses\" limit 100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query cache\n",
    "store = {}\n",
    "\n",
    "def prefetch_query(n):\n",
    "    if n not in store:\n",
    "        store[n] = pd.read_sql(sql + n, conn)        \n",
    "    return store[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes of patient population to evaluate\n",
    "patient_population = ['10', '100', '1000', '10000', '100000']\n",
    "# how many times to run test to calculate mean/std dev\n",
    "default_repetitions = 1\n",
    "\n",
    "def show_timings(df):\n",
    "    q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "    print('Method used     :', q.tail(1)['faux_method'].iloc[0])\n",
    "    print('Time for query  :', (pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0].total_seconds())\n",
    "    print('Time for fauxify:', (pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0].total_seconds())\n",
    "    print('Size of dataset :', len(df), 'rows')\n",
    "\n",
    "# rerun_query option doesn't time fauxify method... need to fix that\n",
    "def time_method(kfpd, repetitions = default_repetitions, verbose = True, rerun_query = True):\n",
    "    for n in patient_population:\n",
    "        fdf = None\n",
    "        # track each run for calculations\n",
    "        query_timings = []\n",
    "        fauxify_timings = []\n",
    "        for i in range(1, repetitions + 1):\n",
    "            # if dataframe provided, don't need to re-run query\n",
    "            if rerun_query:\n",
    "                fdf=kfpd.read_sql(sql + n,conn)\n",
    "                q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "                query_timings.append((pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0].total_seconds())\n",
    "                fauxify_timings.append((pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0].total_seconds())\n",
    "            else:\n",
    "                df = prefetch_query(n)\n",
    "                start = datetime.datetime.now()\n",
    "                fdf=kfpd.plugin.fauxify(df)\n",
    "                fauxify_timings.append((datetime.datetime.now() - start).total_seconds())\n",
    "            if verbose:\n",
    "                print('Iteration ', i, 'of ', repetitions)\n",
    "                print('Method used              :', type(kfpd.plugin).__name__)\n",
    "                print('Size of dataset returned :', len(fdf), 'rows')\n",
    "                if rerun_query:\n",
    "                    print('Time for query           :', query_timings[-1])\n",
    "                print('Time for fauxify         :', fauxify_timings[-1])\n",
    "        print('Method used             :', type(kfpd.plugin).__name__)\n",
    "        print('Size of dataset returned:', len(fdf), 'rows')\n",
    "        print('    Fauxify Mean   :', np.mean(fauxify_timings))\n",
    "        print('    Fauxify Std Dev:', np.std(fauxify_timings))\n",
    "        if rerun_query:\n",
    "            print('    Query Mean   :', np.mean(query_timings))\n",
    "            print('    Query Std Dev:', np.std(query_timings))\n",
    "        else:\n",
    "            print('    See previous run for query timings')\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from kungfauxpandas import KungFauxPandas, TrivialPlugin, DataSynthesizerPlugin, KDEPlugin, KFP_DataDescriber\n",
    "kfpd = KungFauxPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfpd.plugin = TrivialPlugin()\n",
    "#fdf = time_method(kfpd, verbose = False, repetitions = 10)\n",
    "#fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = TrivialPlugin()\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density Estimator Plugin testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = KDEPlugin(verbose = False, mode='independent_attribute_mode')\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = KDEPlugin(verbose = False, mode='correlated_attribute_mode')\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSynthesizer, two different methods with no configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode')\n",
    "#for n in ['10', '100', '1000', '10000', '100000']:\n",
    "#    fdf=kfpd.read_sql(sql + n,conn)\n",
    "#    show_timings(fdf)\n",
    "\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode')\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode')\n",
    "#for n in ['10', '100', '1000', '10000', '100000']:\n",
    "#    fdf=kfpd.read_sql(sql + n,conn)\n",
    "#    show_timings(fdf)\n",
    "\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode')\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try DataSynthesizerPlugin with some manual configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True,\n",
    "                                                              'Code': True,\n",
    "                                                              'Type': True,\n",
    "                                                              'MaxScore': False,\n",
    "                                                              'MinScore': False,\n",
    "                                                              'NumLoggedScores': False}\n",
    "                                   )\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True,\n",
    "                                                              'Code': True,\n",
    "                                                              'Type': True,\n",
    "                                                              'MaxScore': False,\n",
    "                                                              'MinScore': False,\n",
    "                                                              'NumLoggedScores': False})\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing changes to degree_of_bayesian_network\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True,\n",
    "                                                              'Code': True,\n",
    "                                                              'Type': True,\n",
    "                                                              'MaxScore': False,\n",
    "                                                              'MinScore': False,\n",
    "                                                              'NumLoggedScores': False},\n",
    "                                   degree_of_bayesian_network = 3) # default is 2\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False, repetitions = 10)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'unique_id': [40552133, 83299697, 96360391, 43551783, 92110570, 87411981, 26772988, 87390284, 34538374, 13208258],\n",
    "                         #'datetime': ['2017-11-09 02:26:13', '2017-07-20 20:35:41', '2017-12-23 22:48:30', '2017-10-04 05:19:36', '2017-10-15 04:03:31', '2017-08-12 11:35:34', '2017-08-07 12:57:29', '2017-09-20 12:17:48', '2017-08-23 12:39:54', '2017-06-29 07:59:25'],\n",
    "                         'alpha_numeric_code': ['A4152', 'A414', 'A400', 'A392', 'A4151', 'A392', 'A4181', 'P369', 'B377', 'R6521'],\n",
    "                         'constant': ['constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value', 'constant_value'],\n",
    "                         'categorical' : ['category1', 'category2', 'category1', 'category1', 'category2', 'category1', 'category2', 'category1', 'category2', 'category3'],\n",
    "                         #'float_score': [30.80887770115334, 31.647178703213896, 33.23121156661242, 33.64713140102367, 33.07404123596502, 34.206309535666364, 34.90974444556692, 39.06948372169004, 35.94952085309618, 29.5140595543271],\n",
    "                         'int_score': [294, 286, 278, 272, 256, 242, 216, 210, 208, 190]})\n",
    "\n",
    "kfpd.plugin = TrivialPlugin()\n",
    "fdf=kfpd.plugin.fauxify(test_df)\n",
    "print(fdf.head())\n",
    "\n",
    "kfpd.plugin = KDEPlugin(verbose = False)\n",
    "fdf=kfpd.plugin.fauxify(test_df)\n",
    "print(fdf.head())\n",
    "\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode=\"independent_attribute_mode\")\n",
    "fdf=kfpd.plugin.fauxify(test_df)\n",
    "print(fdf.head())\n",
    "\n",
    "test_df.to_csv('sample_data_no_dates.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
