{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# flag to control where data is loaded to\n",
    "mode = 'psycopg2'\n",
    "\n",
    "# sqlite stuff\n",
    "if mode == 'sqlite3':\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(\"../../data/sepsis.db\")\n",
    "    cursor = conn.cursor()\n",
    "elif mode == 'psycopg2': # alternatively use postgresql\n",
    "    import psycopg2\n",
    "    connect_str = \"dbname='sepsis' user='sepsis' host='localhost' \" + \\\n",
    "                  \"password='sepsis'\"\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "qlog_conn = sqlite3.connect('../../data/kfp_log.db')\n",
    "q_cursor = qlog_conn.cursor()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "# because names are created as case sensistive in postgres, must be quoted...\n",
    "# should probably fix that...\n",
    "sql = '''\n",
    "SELECT d.\"SubjectId\",\n",
    "    d.\"EncounterId\",\n",
    "    d.\"Source\",\n",
    "    -- d.StartDate,\n",
    "    d.\"Code\",\n",
    "    d.\"Type\",\n",
    "    MAX(\"FlowsheetValue\") AS MaxScore,\n",
    "    -- AVG(\"FlowsheetValue\") AS MeanScore,\n",
    "    MIN(\"FlowsheetValue\") AS MinScore,\n",
    "    COUNT(\"FlowsheetValue\") AS NumLoggedScores\n",
    " FROM diagnoses d\n",
    " LEFT JOIN flowsheet f\n",
    " ON d.\"EncounterId\" = f.\"EncounterId\"\n",
    " GROUP BY d.\"SubjectId\", d.\"EncounterId\", d.\"Source\", d.\"Code\", d.\"Type\"\n",
    " ORDER BY NumLoggedScores DESC\n",
    " limit\n",
    "'''\n",
    "# timing this query on databases\n",
    "# df = pd.read_sql(sql,conn)\n",
    "# sqlite - 42 to 60 seconds\n",
    "# postgres - 30 seconds\n",
    "\n",
    "#sql = 'SELECT subjectid, encounterid, source, code, type FROM \"diagnoses\" limit 100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_timings(df):\n",
    "    q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "    print('Method used     :', q.tail(1)['faux_method'].iloc[0])\n",
    "    print('Time for query  :', (pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0])\n",
    "    print('Time for fauxify:', (pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0])\n",
    "    print('Size of dataset :', len(df), 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from kungfauxpandas import KungFauxPandas, TrivialPlugin, DataSynthesizerPlugin, KDEPlugin\n",
    "kfpd = KungFauxPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = TrivialPlugin()\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = KDEPlugin()\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSynthesizer, two different methods with no configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode')\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode')\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try DataSynthesizerPlugin with some manual configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True}\n",
    "                                   )\n",
    "for n in ['10']: #, '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True}\n",
    "                                   )\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_of_bayesian_network\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True},\n",
    "                                    degree_of_bayesian_network = 3 # default is 2\n",
    "                                   )\n",
    "for n in ['10']: #, '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
