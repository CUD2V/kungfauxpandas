{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# flag to control where data is loaded to\n",
    "mode = 'psycopg2'\n",
    "\n",
    "# how many times to run each test for tracking mean/std dev\n",
    "\n",
    "# sqlite stuff\n",
    "if mode == 'sqlite3':\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(\"../../data/sepsis.db\")\n",
    "    cursor = conn.cursor()\n",
    "elif mode == 'psycopg2': # alternatively use postgresql\n",
    "    import psycopg2\n",
    "    connect_str = \"dbname='sepsis' user='sepsis' host='localhost' \" + \\\n",
    "                  \"password='sepsis'\"\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "qlog_conn = sqlite3.connect('../../data/kfp_log.db')\n",
    "q_cursor = qlog_conn.cursor()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "# because names are created as case sensistive in postgres, must be quoted...\n",
    "# should probably fix that...\n",
    "sql = '''\n",
    "SELECT d.\"SubjectId\",\n",
    "    d.\"EncounterId\",\n",
    "    d.\"Source\",\n",
    "    -- d.StartDate,\n",
    "    d.\"Code\",\n",
    "    d.\"Type\",\n",
    "    MAX(\"FlowsheetValue\") AS MaxScore,\n",
    "    -- AVG(\"FlowsheetValue\") AS MeanScore,\n",
    "    MIN(\"FlowsheetValue\") AS MinScore,\n",
    "    COUNT(\"FlowsheetValue\") AS NumLoggedScores\n",
    " FROM diagnoses d\n",
    " LEFT JOIN flowsheet f\n",
    " ON d.\"EncounterId\" = f.\"EncounterId\"\n",
    " GROUP BY d.\"SubjectId\", d.\"EncounterId\", d.\"Source\", d.\"Code\", d.\"Type\"\n",
    " ORDER BY NumLoggedScores DESC\n",
    " limit\n",
    "'''\n",
    "# timing this query on databases\n",
    "# df = pd.read_sql(sql,conn)\n",
    "# sqlite - 42 to 60 seconds\n",
    "# postgres - 30 seconds\n",
    "\n",
    "#sql = 'SELECT subjectid, encounterid, source, code, type FROM \"diagnoses\" limit 100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query cache\n",
    "store = {}\n",
    "\n",
    "def prefetch_query(n):\n",
    "    if n not in store:\n",
    "        store[n] = pd.read_sql(sql + n, conn)        \n",
    "    return store[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes of patient population to evaluate\n",
    "patient_population = ['10', '100', '1000', '10000', '100000']\n",
    "# how many times to run test to calculate mean/std dev\n",
    "default_repetitions = 1\n",
    "# track each run for calculations\n",
    "query_timings = []\n",
    "fauxify_timings = []\n",
    "\n",
    "def show_timings(df):\n",
    "    q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "    print('Method used     :', q.tail(1)['faux_method'].iloc[0])\n",
    "    print('Time for query  :', (pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0].total_seconds())\n",
    "    print('Time for fauxify:', (pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0].total_seconds())\n",
    "    print('Size of dataset :', len(df), 'rows')\n",
    "\n",
    "# rerun_query option doesn't time fauxify method... need to fix that\n",
    "def time_method(kfpd, repetitions = default_repetitions, verbose = True, rerun_query = True):\n",
    "    for n in patient_population:\n",
    "        for i in range(1, repetitions + 1):\n",
    "            # if dataframe provided, don't need to re-run query\n",
    "            if rerun_query:\n",
    "                fdf=kfpd.read_sql(sql + n,conn)\n",
    "                q = pd.read_sql(\"SELECT * FROM kfp_log order by fauxify_end\",qlog_conn)\n",
    "                query_timings.append((pd.to_datetime(q.tail(1)['query_end']) - pd.to_datetime(q.tail(1)['query_start'])).iloc[0].total_seconds())\n",
    "                fauxify_timings.append((pd.to_datetime(q.tail(1)['fauxify_end']) - pd.to_datetime(q.tail(1)['fauxify_start'])).iloc[0].total_seconds())\n",
    "            else:\n",
    "                df = prefetch_query(n)\n",
    "                start = datetime.datetime.now()\n",
    "                fdf=kfpd.plugin.fauxify(df)\n",
    "                fauxify_timings.append((datetime.datetime.now() - start).total_seconds())\n",
    "            if verbose:\n",
    "                print('Iteration ', i, 'of ', repetitions)\n",
    "                print('Method used              :', q.tail(1)['faux_method'].iloc[0])\n",
    "                print('Size of dataset returned :', len(fdf), 'rows')\n",
    "                if rerun_query:\n",
    "                    print('Time for query           :', query_timings[-1])\n",
    "                print('Time for fauxify         :', fauxify_timings[-1])\n",
    "        print('Method used             :', type(kfpd.plugin).__name__)\n",
    "        print('Size of dataset returned:', len(fdf), 'rows')\n",
    "        print('    Fauxify Mean   :', np.mean(fauxify_timings))\n",
    "        print('    Fauxify Std Dev:', np.std(fauxify_timings))\n",
    "        if rerun_query:\n",
    "            print('    Query Mean   :', np.mean(query_timings))\n",
    "            print('    Query Std Dev:', np.std(query_timings))\n",
    "        else:\n",
    "            print('    See previous run for query timings')\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from kungfauxpandas import KungFauxPandas, TrivialPlugin, DataSynthesizerPlugin, KDEPlugin\n",
    "kfpd = KungFauxPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = TrivialPlugin()\n",
    "fdf = time_method(kfpd)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = TrivialPlugin()\n",
    "fdf = time_method(kfpd, verbose = False, rerun_query = False)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = KDEPlugin(verbose = False)\n",
    "time_method(kfpd, verbose = False, rerun_query = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSynthesizer, two different methods with no configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode')\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode')\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try DataSynthesizerPlugin with some manual configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True}\n",
    "                                   )\n",
    "for n in ['10']: #, '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfpd.plugin = DataSynthesizerPlugin(mode='independent_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True}\n",
    "                                   )\n",
    "for n in ['10', '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_of_bayesian_network\n",
    "kfpd.plugin = DataSynthesizerPlugin(mode='correlated_attribute_mode',\n",
    "                                    candidate_keys = {'SubjectId': True, 'EncounterId': True},\n",
    "                                    categorical_attributes = {'Source': True, 'Code': True, 'Type': True},\n",
    "                                    degree_of_bayesian_network = 3 # default is 2\n",
    "                                   )\n",
    "for n in ['10']: #, '100', '1000', '10000', '100000']:\n",
    "    fdf=kfpd.read_sql(sql + n,conn)\n",
    "    show_timings(fdf)\n",
    "\n",
    "fdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
